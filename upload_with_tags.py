<<<<<<< HEAD
import os
import time
import requests
from urllib.parse import urljoin
from transformers import BlipProcessor, BlipForConditionalGeneration
from PIL import Image
import nltk
from nltk import pos_tag, word_tokenize

# åˆå§‹åŒ– NLTK
nltk.download('punkt', quiet=True)
nltk.download('averaged_perceptron_tagger', quiet=True)

# BLIP æ¨¡åž‹
print("ðŸ”„ è¼‰å…¥ BLIP æ¨¡åž‹ä¸­...")
processor = BlipProcessor.from_pretrained("Salesforce/blip-image-captioning-base")
model = BlipForConditionalGeneration.from_pretrained("Salesforce/blip-image-captioning-base")

# è¨­å®š
BACKEND_URL = "https://liff-test-9xse.onrender.com"
USER_ID = "test_user"  # å¯ä»¥æ”¹æˆä½ çš„ LINE user_id
CHECK_INTERVAL = 30  # æ¯ 30 ç§’æª¢æŸ¥ä¸€æ¬¡
TEMP_FOLDER = "temp_images"
os.makedirs(TEMP_FOLDER, exist_ok=True)

def extract_adjectives(text):
    tokens = word_tokenize(text)
    tagged = pos_tag(tokens)
    return [word for word, pos in tagged if pos in ('JJ', 'JJR', 'JJS')]

def generate_tags(image_path):
    raw_image = Image.open(image_path).convert('RGB')
    inputs = processor(raw_image, return_tensors="pt")
    out = model.generate(**inputs)
    caption = processor.decode(out[0], skip_special_tokens=True)
    adjectives = extract_adjectives(caption)
    print(f"Caption: {caption}")
    return ",".join(adjectives)

def check_and_update_tags():
    print("ðŸ” æª¢æŸ¥æœªæ¨™è¨˜çš„åœ–ç‰‡...")
    res = requests.get(f"{BACKEND_URL}/wardrobe?user_id={USER_ID}")
    data = res.json()

    for img in data.get("images", []):
        if not img.get("tags"):  # tags ç‚ºç©ºæ‰è™•ç†
            img_url = urljoin(BACKEND_URL, img["path"])
            filename = os.path.basename(img["path"])
            category = img["category"]

            # ä¸‹è¼‰åœ–ç‰‡
            img_path = os.path.join(TEMP_FOLDER, filename)
            with requests.get(img_url, stream=True) as r:
                with open(img_path, "wb") as f:
                    for chunk in r.iter_content(8192):
                        f.write(chunk)

            # ç”Ÿæˆ tags
            tags = generate_tags(img_path)

            # æ›´æ–°å¾Œç«¯
            payload = {
                "user_id": USER_ID,
                "filename": filename,
                "category": category,
                "tags": tags
            }
            requests.post(f"{BACKEND_URL}/update_tags", json=payload)
            print(f"âœ… å·²è£œä¸Š tags: {filename} -> {tags}")

            os.remove(img_path)  # æ¸…é™¤æš«å­˜æª”

if __name__ == "__main__":
    while True:
        check_and_update_tags()
        time.sleep(CHECK_INTERVAL)
=======
import os
import time
import requests
from urllib.parse import urljoin
from transformers import BlipProcessor, BlipForConditionalGeneration
from PIL import Image
import nltk
from nltk import pos_tag, word_tokenize

# åˆå§‹åŒ– NLTK
nltk.download('punkt', quiet=True)
nltk.download('averaged_perceptron_tagger', quiet=True)

# BLIP æ¨¡åž‹
print("ðŸ”„ è¼‰å…¥ BLIP æ¨¡åž‹ä¸­...")
processor = BlipProcessor.from_pretrained("Salesforce/blip-image-captioning-base")
model = BlipForConditionalGeneration.from_pretrained("Salesforce/blip-image-captioning-base")

# è¨­å®š
BACKEND_URL = "https://liff-test-9xse.onrender.com"
USER_ID = "test_user"  # å¯ä»¥æ”¹æˆä½ çš„ LINE user_id
CHECK_INTERVAL = 30  # æ¯ 30 ç§’æª¢æŸ¥ä¸€æ¬¡
TEMP_FOLDER = "temp_images"
os.makedirs(TEMP_FOLDER, exist_ok=True)

def extract_adjectives(text):
    tokens = word_tokenize(text)
    tagged = pos_tag(tokens)
    return [word for word, pos in tagged if pos in ('JJ', 'JJR', 'JJS')]

def generate_tags(image_path):
    raw_image = Image.open(image_path).convert('RGB')
    inputs = processor(raw_image, return_tensors="pt")
    out = model.generate(**inputs)
    caption = processor.decode(out[0], skip_special_tokens=True)
    adjectives = extract_adjectives(caption)
    print(f"Caption: {caption}")
    return ",".join(adjectives)

def check_and_update_tags():
    print("ðŸ” æª¢æŸ¥æœªæ¨™è¨˜çš„åœ–ç‰‡...")
    res = requests.get(f"{BACKEND_URL}/wardrobe?user_id={USER_ID}")
    data = res.json()

    for img in data.get("images", []):
        if not img.get("tags"):  # tags ç‚ºç©ºæ‰è™•ç†
            img_url = urljoin(BACKEND_URL, img["path"])
            filename = os.path.basename(img["path"])
            category = img["category"]

            # ä¸‹è¼‰åœ–ç‰‡
            img_path = os.path.join(TEMP_FOLDER, filename)
            with requests.get(img_url, stream=True) as r:
                with open(img_path, "wb") as f:
                    for chunk in r.iter_content(8192):
                        f.write(chunk)

            # ç”Ÿæˆ tags
            tags = generate_tags(img_path)

            # æ›´æ–°å¾Œç«¯
            payload = {
                "user_id": USER_ID,
                "filename": filename,
                "category": category,
                "tags": tags
            }
            requests.post(f"{BACKEND_URL}/update_tags", json=payload)
            print(f"âœ… å·²è£œä¸Š tags: {filename} -> {tags}")

            os.remove(img_path)  # æ¸…é™¤æš«å­˜æª”

if __name__ == "__main__":
    while True:
        check_and_update_tags()
        time.sleep(CHECK_INTERVAL)
>>>>>>> 2bbfa7a7c2328490db4598e217cfabed6bc0ed59
